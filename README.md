# ğŸ¤–âœ¨ **HandWavers: Humanoid Hand-Waving Behavior Learning with Isaac Lab**

Teach a humanoid robot to wave *rhythmically* using reinforcement learning!
HandWavers is an external Isaac Lab project built around **PPO (Proximal Policy Optimization)** and **Isaac Labâ€™s manager-based RL workflow**.

---
<p align="left"> <img src="https://img.shields.io/github/stars/ThejasDevadiga/Reinforcement-learning-Humanoid-robot-wavehand?style=flat-square&logo=github" /> <img src="https://img.shields.io/badge/License-BSD--3--Clause-blue?style=flat-square" /> <img src="https://img.shields.io/badge/Python-3.11-blue?style=flat-square&logo=python" /> <img src="https://img.shields.io/badge/Isaac%20Lab-0.5+-orange?style=flat-square&logo=nvidia" /> <img src="https://img.shields.io/badge/Framework-skrl-green?style=flat-square" /> </p>

## ğŸŒŸ **Overview**

HandWavers trains a humanoid robot to perform expressive hand-waving motions using:

* ğŸ§  **PPO** (skrl implementation)
* ğŸ—ï¸ **Isaac Lab manager-based environment design**
* âš™ï¸ **Modular actions, observations, rewards, and terminations**
* âš¡ **Massively parallel vectorized simulation**

```
â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—     â–ˆâ–ˆâ•—    â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— 
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆ   â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆ   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘ â–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•
â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆ   â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—
â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ â•‘    â•šâ–ˆâ–ˆâ–ˆâ•”â–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•”â• â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘
â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•      â•šâ•â•â•â•šâ•â•â• â•šâ•â•  â•šâ•â•  â•šâ•â•â•â•  â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•

           Humanoid Hand-Waving using Isaac Lab + PPO (skrl)
```

## ğŸ§© **Prerequisites**

| Component     | Requirement                                |
| ------------- | ------------------------------------------ |
| ğŸ–¥ï¸ **OS**    | Ubuntu 20.04 / 22.04                       |
| ğŸ® **GPU**    | NVIDIA GPU (8GB+ VRAM, tested on RTX 5070) |
| ğŸ§ª **CUDA**   | 12.x                               |
| ğŸ **Python** | 3.11 (required for Isaac Sim 5.0+)         |
| ğŸ§  **RAM**    | 32GB+ recommended                          |
| ğŸ’¾ **Disk**   | 100GB+ free                                |

---

## âš™ï¸ **Installation**

### **ğŸ“¦ Step 1: Install Isaac Sim (from source)**

```bash
cd ~/Documents/projects/RL
git clone https://github.com/isaac-sim/IsaacSim.git isaacsim
cd isaacsim

./build.sh       # â³ Takes 1â€“2 hours

source setup_conda_env.sh
```

---

### **ğŸ”§ Step 2: Install Isaac Lab**

```bash
cd ~/Documents/projects/RL
git clone https://github.com/isaac-sim/IsaacLab.git IsaacLab

cd IsaacLab
pip install -e .

pip install -e .[skrl]    # RL backend
# or: pip install -e .[all]
```

---

### **ğŸ¤ Step 3: Install HandWavers**

```bash
cd ~/Documents/projects/RL/customTask
git clone <your-repo-url> hand_wavers
cd hand_wavers

pip install -e source/hand_wavers
```

**Verify installation:**

```bash
python scripts/list_envs.py
# Should show: Template-Hand-Wavers-v0 ğŸ‰
```

---

### **ğŸ› ï¸ Step 4: System Configuration (important!)**

Increase inotify limits (required for Isaac Sim):

```bash
sudo sysctl -w fs.inotify.max_user_watches=524288
echo fs.inotify.max_user_watches=524288 | sudo tee -a /etc/sysctl.conf
sudo sysctl -p
```

---

## ğŸ“ **Project Structure**

```
hand_wavers/
â”œâ”€â”€ source/hand_wavers/
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â””â”€â”€ manager_based/
â”‚   â”‚       â”œâ”€â”€ hand_wavers_env.py      # ğŸŒŸ Main environment
â”‚   â”‚       â””â”€â”€ hand_wavers_env_cfg.py  # âš™ï¸ Config
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ skrl/
â”‚   â”‚   â”œâ”€â”€ train.py         # ğŸš€ Training
â”‚   â”‚   â””â”€â”€ zero_agent.py    # ğŸ§ª Baseline (zero actions)
â”‚   â””â”€â”€ list_envs.py
â””â”€â”€ README.md
```


# ğŸ§© Architecture Diagram
```
HandWavers System Architecture
                           +------------------------------+
                           |         PPO Agent            |
                           |   (Policy + Value networks)  |
                           +---------------+--------------+
                                           |
                                           | actions
                                           v
+------------------------------+    +-------+--------+    +------------------------+
|      Observation Manager     | <--| Action Manager |--> |   Reward Manager       |
|  (joint states, base pose,   |    | (arm joints,   |    |  (tracking, upright,   |
|   velocities, contacts, etc) |    |  wave control) |    |   energy, limits...)   |
+--------------+---------------+    +-------+--------+    +-----------+------------+
               ^                                    |                    |
               |                                    |                    v
      observations                         joint commands         reward sum
               |                                    |                    |
               +---------------------------------------------------------+
                                           Environment
                                          (Isaac Lab)
```


# ğŸ‹ï¸â€â™‚ï¸ **Training**

### ğŸš€ **Quick Start**

```bash
conda activate rltrain311
cd ~/Documents/projects/RL/customTask/hand_wavers

python scripts/skrl/train.py --task=Template-Hand-Wavers-v0 --headless
```

### ğŸ›ï¸ Custom Settings

```bash
python scripts/skrl/train.py \
  --task=Template-Hand-Wavers-v0 \
  --num_envs=1024 \
  --max_iterations=1000 \
  --headless
```

---

## ğŸ“Š **Training Parameters (PPO)**

Key PPO hyperparameters:

```python
"learning_rate": 3e-4,
"ratio_clip": 0.2,
"discount_factor": 0.99,
"lambda": 0.95,
"entropy_loss_scale": 0.01,
"value_loss_scale": 1.0,
"rollouts": 4096,
"mini_batches": 4,
"learning_epochs": 5,
"grad_norm_clip": 1.0,
```

âœ” KL-adaptive learning rate
âœ” Running state/value normalization
âœ” Value clipping
âœ” Reward scaling

---

## ğŸ“ˆ **Monitoring Training**

Start TensorBoard:

```bash
tensorboard --logdir logs/skrl/
```

Includes:

* ğŸ“ˆ Episode Reward
* ğŸ” Per-term reward breakdown
* ğŸ“‰ Value & policy loss
* â™»ï¸ KL divergence
* ğŸ”¥ Entropy

---

## ğŸ¬ **Evaluation & Testing**

```bash
# Run trained policy
python scripts/skrl/train.py \
  --task=Template-Hand-Wavers-v0 \
  --checkpoint=logs/skrl/<timestamp>/checkpoint_1000.pt \
  --num_envs=1
```

Test standing (zero actions):

```bash
python scripts/skrl/zero_agent.py --task=Template-Hand-Wavers-v0 --num_envs=1
```

---

# ğŸ§  **Algorithm Details (PPO)**

HandWavers uses skrlâ€™s PPO implementation with:

* ğŸŒŠ **GAE (Î» = 0.95)**
* âœ‚ï¸ **Clipped surrogate objective**
* ğŸ§Š **Value function clipping**
* â™»ï¸ **KL-adaptive LR**
* ğŸ§® **RunningStandardScaler**
* ğŸ§± **Mini-batch updates**
* ğŸ›¡ï¸ **Gradient clipping**

---

## ğŸ—ï¸ **Environment Design**

Modular Isaac Lab managers:

* ğŸ® **Action Manager** â€“ joint commands
* ğŸ‘ï¸ **Observation Manager** â€“ ~87-dim state
* ğŸ¯ **Reward Manager** â€“ shaping & tracking
* ğŸ›‘ **Termination Manager** â€“ timeout / fall
* ğŸ² **Event Manager** â€“ randomization

---

## ğŸ† **Reward Function**

Main reward components:

```
r = 1.0 * progress
  + 2.0 * alive
  + 0.1 * upright
  + 0.5 * move_to_target
  - 0.01 * action_l2
  - 0.005 * energy
  - 0.25 * joint_pos_limits
```

â±ï¸ Scaled by dt = 0.0167

---

# ğŸ› ï¸ Troubleshooting

### âŒ Out of GPU Memory?

```bash
python scripts/skrl/train.py --num_envs=512
```

### âŒ "No space left on device"

Increase inotify (see above).

### âš¡ Performance Tips

* Use `--headless`
* Increase `num_envs` (if VRAM allows)
* Enable Fabric (default)
* Reduce rendering frequency

---

# ğŸ§© Customization

To adapt for **hand-waving**:

* â• Add hand pose/velocity observations
* ğŸ¯ Replace locomotion rewards with gesture targets
* ğŸ¦¾ Modify action space to focus on arm joints
* ğŸ›‘ Add custom termination / success criteria

Edit:
`source/hand_wavers/tasks/manager_based/hand_wavers_env_cfg.py`

---

# ğŸ“š References

* ğŸ“˜ Isaac Lab Docs
* ğŸ“™ skrl Documentation
* ğŸ“„ PPO Paper (Schulman et al. 2017)

---

# ğŸ“œ License

BSD-3-Clause (inherits Isaac Labâ€™s license)

---
